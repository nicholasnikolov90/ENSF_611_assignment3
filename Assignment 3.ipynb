{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
    "### Due: October 24 at 11:59pm\n",
    "\n",
    "### Name: Nick Nikolov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression (14.5 marks)\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cement   slag    ash  water  splast  coarse   fine  age\n",
      "0      540.0    0.0    0.0  162.0     2.5  1040.0  676.0   28\n",
      "1      540.0    0.0    0.0  162.0     2.5  1055.0  676.0   28\n",
      "2      332.5  142.5    0.0  228.0     0.0   932.0  594.0  270\n",
      "3      332.5  142.5    0.0  228.0     0.0   932.0  594.0  365\n",
      "4      198.6  132.4    0.0  192.0     0.0   978.4  825.5  360\n",
      "...      ...    ...    ...    ...     ...     ...    ...  ...\n",
      "1025   276.4  116.0   90.3  179.6     8.9   870.1  768.3   28\n",
      "1026   322.2    0.0  115.6  196.0    10.4   817.9  813.4   28\n",
      "1027   148.5  139.4  108.6  192.7     6.1   892.4  780.0   28\n",
      "1028   159.1  186.7    0.0  175.6    11.3   989.6  788.9   28\n",
      "1029   260.9  100.5   78.3  200.6     8.6   864.5  761.5   28\n",
      "\n",
      "[1030 rows x 8 columns]\n",
      "0       79.986111\n",
      "1       61.887366\n",
      "2       40.269535\n",
      "3       41.052780\n",
      "4       44.296075\n",
      "          ...    \n",
      "1025    44.284354\n",
      "1026    31.178794\n",
      "1027    23.696601\n",
      "1028    32.768036\n",
      "1029    32.401235\n",
      "Name: strength, Length: 1030, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "\n",
    "X, y = load_concrete()\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0 marks)\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "3. Implement each machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training Accuracy                       Validation Accuracy           \\\n",
      "                 DT         RF         GB                  DT       RF   \n",
      "0         47.279761  73.447331  32.723495           50.292588  3.37944   \n",
      "\n",
      "              \n",
      "          GB  \n",
      "0  22.783221  \n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "tree = DecisionTreeRegressor(random_state=0, max_depth=5)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=10, max_features = 1.0, random_state=0, max_depth=5)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "gb_model = GradientBoostingRegressor(random_state=0, n_estimators=100,  max_depth = 5)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "gb_scores = cross_validate(gb_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "rf_scores = cross_validate(rf_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "tree_scores = cross_validate(tree, X_train, y_train, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    [[tree_scores['train_score'].mean(), tree_scores['test_score'].mean(), rf_scores['train_score'].mean(), rf_scores['test_score'].mean(), gb_scores['train_score'].mean(), gb_scores['test_score'].mean()]],\n",
    "    columns=pd.MultiIndex.from_product([(\"Training Accuracy\", \"Validation Accuracy\"), (\"DT\", \"RF\", \"GB\")])\n",
    ")\n",
    "results = results.multiply(-1)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83539f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training Accuracy                     Validation Accuracy            \\\n",
      "                 DT        RF        GB                  DT        RF   \n",
      "0          0.834465  0.738697  0.885532            0.822623  0.988171   \n",
      "\n",
      "             \n",
      "         GB  \n",
      "0  0.919471  \n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "gb_scores = cross_validate(gb_model, X_train, y_train, cv=5, scoring='r2', return_train_score=True)\n",
    "rf_scores = cross_validate(rf_model, X_train, y_train, cv=5, scoring='r2', return_train_score=True)\n",
    "tree_scores = cross_validate(tree, X_train, y_train, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "results_r2 = pd.DataFrame(\n",
    "    [[tree_scores['train_score'].mean(), tree_scores['test_score'].mean(), rf_scores['train_score'].mean(), rf_scores['test_score'].mean(), gb_scores['train_score'].mean(), gb_scores['test_score'].mean()]],\n",
    "    columns=pd.MultiIndex.from_product([(\"Training Accuracy\", \"Validation Accuracy\"), (\"DT\", \"RF\", \"GB\")])\n",
    ")\n",
    "\n",
    "print(results_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "2. Out of the models you tested, which model would you select for this dataset and why?\n",
    "3. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "*ANSWER HERE*\n",
    "\n",
    "1. All 3 regressors proviide much better accuracy than the linear models. The linear models all provided roughly 0.62 r2 scores, while these non-linear models are all scoring at least 0.8 on the validation data.\n",
    "\n",
    "2. I think randomforrests would be the best model to use on this dataset. Random forrests had a higher r2 validation score, and a lower mean squared error.\n",
    "\n",
    "3. To increase the accuracy we can increase the depth of the tree. Being careful not to increase the depth too much which would result in overfitting. For the random forrest regressor, we can increase the number of estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "2. In what order did you complete the steps?\n",
    "3. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "4. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "1. Majority was from the Examples tab in D2L, and sklearn documentation.\n",
    "\n",
    "2. Numerical order.\n",
    "\n",
    "3. I didn't use generative AI! (very proud of myself). I think because Assignment 2 was quite similar. Also the lecture notes helped to decide which parameters I needed to add to the models. \n",
    "\n",
    "4. I accidentally tried using classifiers instead of regressors. Classifiers only work on discrete target vectors, so I should have recognized instantly. But it took me longer than it should have to realize what was going on!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification (17.5 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (2 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset \n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_wine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TO DO: Import wine dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X, y \u001b[38;5;241m=\u001b[39m load_wine()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(X)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(y)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_wine' is not defined"
     ]
    }
   ],
   "source": [
    "# TO DO: Import wine dataset\n",
    "X, y = load_wine()\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea266921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37a6fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Implement best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d21b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef95947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Print classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "1. How many samples were incorrectly classified in step 5.2? \n",
    "1. In this case, is maximizing precision or recall more important? Why?\n",
    "\n",
    "*YOUR ANSWERS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (3 marks)\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fea72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c3b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f018c-52cd-401d-83bd-ab2f0af45bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "References\n",
    "1. https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html#sphx-glr-auto-examples-tree-plot-tree-regression-py\n",
    "2. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "3. https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor\n",
    "4. Aeberhard,Stefan and Forina,M.. (1991). Wine. UCI Machine Learning Repository. https://doi.org/10.24432/C5PC7J.\n",
    "5. Yeh, I-C. “Modeling of strength of high-performance concrete using artificial neural networks.” Cement and Concrete research 28.12 (1998): 1797-1808.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
